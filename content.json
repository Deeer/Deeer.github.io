{"meta":{"title":"🦖 Deeer 👨‍💻","subtitle":"士不可以不弘毅，任重而道远。","description":"代码手工艺人 | Love Linux  | 追求体验","author":"Deeer","url":"http://deeer.github.io","root":"/"},"pages":[{"title":"about","date":"2015-07-26T08:45:00.000Z","updated":"2020-09-19T12:06:43.885Z","comments":true,"path":"about/index.html","permalink":"http://deeer.github.io/about/index.html","excerpt":"","text":"HEY , THIS IS DEEER."},{"title":"tags","date":"2015-06-02T16:09:09.000Z","updated":"2015-06-06T17:47:06.000Z","comments":true,"path":"tags/index.html","permalink":"http://deeer.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2015-07-26T09:11:08.000Z","updated":"2018-02-27T14:59:45.000Z","comments":true,"path":"categories/index.html","permalink":"http://deeer.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"深入理解GCD","slug":"深入理解GCD","date":"2021-03-29T15:06:14.000Z","updated":"2021-04-07T17:14:39.412Z","comments":true,"path":"2021/03/29/深入理解GCD/","link":"","permalink":"http://deeer.github.io/2021/03/29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3GCD/","excerpt":"队列在GCD中包含了四种队列 ： 主队列、 全局队列、 管理队列、自定义队列。这里我们一一来看，其中的实现逻辑。","text":"队列在GCD中包含了四种队列 ： 主队列、 全局队列、 管理队列、自定义队列。这里我们一一来看，其中的实现逻辑。 自定义队列队列底层使用dispatch_queue_create进行创建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161dispatch_queue_tdispatch_queue_create(const char *label, dispatch_queue_attr_t attr)&#123; return _dispatch_lane_create_with_target(label, attr, DISPATCH_TARGET_QUEUE_DEFAULT, true);&#125;----------------------------------------// dispatch_queue_t tq 目标队列，队列中实际的任务在target queue 中执行，这里默认传 DISPATCH_TARGET_QUEUE_DEFAULT - NULL// dispatch_queue_attr_t 队列属性 // 从参数中获取qos属性DISPATCH_NOINLINEstatic dispatch_queue_t_dispatch_lane_create_with_target(const char *label, dispatch_queue_attr_t dqa, dispatch_queue_t tq, bool legacy)&#123; // 获取队列属性信息 // dispatch_queue_attr_info_s // typedef struct dispatch_queue_attr_info_s &#123; // dispatch_qos_t dqai_qos : 8; // int dqai_relpri : 8; // uint16_t dqai_overcommit:2; // uint16_t dqai_autorelease_frequency:2; // uint16_t dqai_concurrent:1; // uint16_t dqai_inactive:1; // &#125; dispatch_queue_attr_info_t; dispatch_queue_attr_info_t dqai = _dispatch_queue_attr_to_info(dqa); // // Step 1: Normalize arguments (qos, overcommit, tq) // // 获取队列的qos信息 dispatch_qos_t qos = dqai.dqai_qos; //#if !HAVE_PTHREAD_WORKQUEUE_QOS if (qos == DISPATCH_QOS_USER_INTERACTIVE) &#123; dqai.dqai_qos = qos = DISPATCH_QOS_USER_INITIATED; &#125; if (qos == DISPATCH_QOS_MAINTENANCE) &#123; dqai.dqai_qos = qos = DISPATCH_QOS_BACKGROUND; &#125;#endif // !HAVE_PTHREAD_WORKQUEUE_QOS // overcommit信息 _dispatch_queue_attr_overcommit_t overcommit = dqai.dqai_overcommit; // 如果没有overcommit信息 且 有 targetqueue if (overcommit != _dispatch_queue_attr_overcommit_unspecified &amp;&amp; tq) &#123; // 不能同时指定 overcommit 信息 和 非全局targetqueue if (tq-&gt;do_targetq) &#123; DISPATCH_CLIENT_CRASH(tq, &quot;Cannot specify both overcommit and &quot; &quot;a non-global target queue&quot;); &#125; &#125; if (tq &amp;&amp; dx_type(tq) == DISPATCH_QUEUE_GLOBAL_ROOT_TYPE) &#123; // Handle discrepancies between attr and target queue, attributes win if (overcommit == _dispatch_queue_attr_overcommit_unspecified) &#123; if (tq-&gt;dq_priority &amp; DISPATCH_PRIORITY_FLAG_OVERCOMMIT) &#123; overcommit = _dispatch_queue_attr_overcommit_enabled; &#125; else &#123; overcommit = _dispatch_queue_attr_overcommit_disabled; &#125; &#125; if (qos == DISPATCH_QOS_UNSPECIFIED) &#123; qos = _dispatch_priority_qos(tq-&gt;dq_priority); &#125; tq = NULL; &#125; else if (tq &amp;&amp; !tq-&gt;do_targetq) &#123; // target 是 pthread 或者runloop的root queue ，设置QOS 或者 overcommit 是不允许的 // target is a pthread or runloop root queue, setting QoS or overcommit // is disallowed if (overcommit != _dispatch_queue_attr_overcommit_unspecified) &#123; DISPATCH_CLIENT_CRASH(tq, &quot;Cannot specify an overcommit attribute &quot; &quot;and use this kind of target queue&quot;); &#125; &#125; else &#123; if (overcommit == _dispatch_queue_attr_overcommit_unspecified) &#123; // Serial queues default to overcommit! // 串行队列的overcommit 是 启用的 overcommit = dqai.dqai_concurrent ? _dispatch_queue_attr_overcommit_disabled : _dispatch_queue_attr_overcommit_enabled; &#125; &#125; // 如果没有target queue， 设置获取从root queue 中去获取 if (!tq) &#123; // 获取root queue tq = _dispatch_get_root_queue( qos == DISPATCH_QOS_UNSPECIFIED ? DISPATCH_QOS_DEFAULT : qos, overcommit == _dispatch_queue_attr_overcommit_enabled)-&gt;_as_dq; if (unlikely(!tq)) &#123; DISPATCH_CLIENT_CRASH(qos, &quot;Invalid queue attribute&quot;); &#125; &#125; // // Step 2: Initialize the queue // if (legacy) &#123; // if any of these attributes is specified, use non legacy classes if (dqai.dqai_inactive || dqai.dqai_autorelease_frequency) &#123; legacy = false; &#125; &#125; const void *vtable; dispatch_queue_flags_t dqf = legacy ? DQF_MUTABLE : 0; // if (dqai.dqai_concurrent) &#123; vtable = DISPATCH_VTABLE(queue_concurrent); &#125; else &#123; vtable = DISPATCH_VTABLE(queue_serial); &#125; // auto relase switch (dqai.dqai_autorelease_frequency) &#123; case DISPATCH_AUTORELEASE_FREQUENCY_NEVER: dqf |= DQF_AUTORELEASE_NEVER; break; case DISPATCH_AUTORELEASE_FREQUENCY_WORK_ITEM: dqf |= DQF_AUTORELEASE_ALWAYS; break; &#125; if (label) &#123; const char *tmp = _dispatch_strdup_if_mutable(label); if (tmp != label) &#123; dqf |= DQF_LABEL_NEEDS_FREE; label = tmp; &#125; &#125; dispatch_lane_t dq = _dispatch_object_alloc(vtable, sizeof(struct dispatch_lane_s)); _dispatch_queue_init(dq, dqf, dqai.dqai_concurrent ? DISPATCH_QUEUE_WIDTH_MAX : 1, DISPATCH_QUEUE_ROLE_INNER | (dqai.dqai_inactive ? DISPATCH_QUEUE_INACTIVE : 0)); dq-&gt;dq_label = label; dq-&gt;dq_priority = _dispatch_priority_make((dispatch_qos_t)dqai.dqai_qos, dqai.dqai_relpri); if (overcommit == _dispatch_queue_attr_overcommit_enabled) &#123; dq-&gt;dq_priority |= DISPATCH_PRIORITY_FLAG_OVERCOMMIT; &#125; if (!dqai.dqai_inactive) &#123; // 从target 继承优先级 _dispatch_queue_priority_inherit_from_target(dq, tq); _dispatch_lane_inherit_wlh_from_target(dq, tq); &#125; _dispatch_retain(tq); dq-&gt;do_targetq = tq; _dispatch_object_debug(dq, &quot;%s&quot;, __func__); return _dispatch_trace_queue_create(dq)._dq;&#125; 全局队列 - dispatch_get_global_queue1234567891011121314151617181920212223dispatch_queue_global_tdispatch_get_global_queue(long priority, unsigned long flags)&#123; dispatch_assert(countof(_dispatch_root_queues) == DISPATCH_ROOT_QUEUE_COUNT); if (flags &amp; ~(unsigned long)DISPATCH_QUEUE_OVERCOMMIT) &#123; return DISPATCH_BAD_INPUT; &#125; dispatch_qos_t qos = _dispatch_qos_from_queue_priority(priority);#if !HAVE_PTHREAD_WORKQUEUE_QOS if (qos == QOS_CLASS_MAINTENANCE) &#123; qos = DISPATCH_QOS_BACKGROUND; &#125; else if (qos == QOS_CLASS_USER_INTERACTIVE) &#123; qos = DISPATCH_QOS_USER_INITIATED; &#125;#endif if (qos == DISPATCH_QOS_UNSPECIFIED) &#123; return DISPATCH_BAD_INPUT; &#125; return _dispatch_get_root_queue(qos, flags &amp; DISPATCH_QUEUE_OVERCOMMIT);&#125; 这里我们可以看到全局队列最终调用的是_dispatch_get_root_queue 123456789DISPATCH_ALWAYS_INLINE DISPATCH_CONSTstatic inline dispatch_queue_global_t_dispatch_get_root_queue(dispatch_qos_t qos, bool overcommit)&#123; if (unlikely(qos &lt; DISPATCH_QOS_MIN || qos &gt; DISPATCH_QOS_MAX)) &#123; DISPATCH_CLIENT_CRASH(qos, &quot;Corrupted priority&quot;); &#125; return &amp;_dispatch_root_queues[2 * (qos - 1) + overcommit];&#125; 实际上_dispatch_root_queuess是一个系统硬编码的队列数组 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667struct dispatch_queue_global_s _dispatch_root_queues[] = &#123;#define _DISPATCH_ROOT_QUEUE_IDX(n, flags) \\ ((flags &amp; DISPATCH_PRIORITY_FLAG_OVERCOMMIT) ? \\ DISPATCH_ROOT_QUEUE_IDX_##n##_QOS_OVERCOMMIT : \\ DISPATCH_ROOT_QUEUE_IDX_##n##_QOS)#define _DISPATCH_ROOT_QUEUE_ENTRY(n, flags, ...) \\ [_DISPATCH_ROOT_QUEUE_IDX(n, flags)] = &#123; \\ DISPATCH_GLOBAL_OBJECT_HEADER(queue_global), \\ .dq_state = DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE, \\ .do_ctxt = _dispatch_root_queue_ctxt(_DISPATCH_ROOT_QUEUE_IDX(n, flags)), \\ .dq_atomic_flags = DQF_WIDTH(DISPATCH_QUEUE_WIDTH_POOL), \\ .dq_priority = flags | ((flags &amp; DISPATCH_PRIORITY_FLAG_FALLBACK) ? \\ _dispatch_priority_make_fallback(DISPATCH_QOS_##n) : \\ _dispatch_priority_make(DISPATCH_QOS_##n, 0)), \\ __VA_ARGS__ \\ &#125; _DISPATCH_ROOT_QUEUE_ENTRY(MAINTENANCE, 0, .dq_label = &quot;com.apple.root.maintenance-qos&quot;, .dq_serialnum = 4, ), _DISPATCH_ROOT_QUEUE_ENTRY(MAINTENANCE, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.maintenance-qos.overcommit&quot;, .dq_serialnum = 5, ), _DISPATCH_ROOT_QUEUE_ENTRY(BACKGROUND, 0, .dq_label = &quot;com.apple.root.background-qos&quot;, .dq_serialnum = 6, ), _DISPATCH_ROOT_QUEUE_ENTRY(BACKGROUND, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.background-qos.overcommit&quot;, .dq_serialnum = 7, ), _DISPATCH_ROOT_QUEUE_ENTRY(UTILITY, 0, .dq_label = &quot;com.apple.root.utility-qos&quot;, .dq_serialnum = 8, ), _DISPATCH_ROOT_QUEUE_ENTRY(UTILITY, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.utility-qos.overcommit&quot;, .dq_serialnum = 9, ), _DISPATCH_ROOT_QUEUE_ENTRY(DEFAULT, DISPATCH_PRIORITY_FLAG_FALLBACK, .dq_label = &quot;com.apple.root.default-qos&quot;, .dq_serialnum = 10, ), _DISPATCH_ROOT_QUEUE_ENTRY(DEFAULT, DISPATCH_PRIORITY_FLAG_FALLBACK | DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.default-qos.overcommit&quot;, .dq_serialnum = 11, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INITIATED, 0, .dq_label = &quot;com.apple.root.user-initiated-qos&quot;, .dq_serialnum = 12, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INITIATED, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.user-initiated-qos.overcommit&quot;, .dq_serialnum = 13, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INTERACTIVE, 0, .dq_label = &quot;com.apple.root.user-interactive-qos&quot;, .dq_serialnum = 14, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INTERACTIVE, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.user-interactive-qos.overcommit&quot;, .dq_serialnum = 15, ),&#125;; 主队列123456789101112131415struct dispatch_queue_static_s _dispatch_main_q = &#123; DISPATCH_GLOBAL_OBJECT_HEADER(queue_main),#if !DISPATCH_USE_RESOLVERS .do_targetq = _dispatch_get_default_queue(true),#endif .dq_state = DISPATCH_QUEUE_STATE_INIT_VALUE(1) | DISPATCH_QUEUE_ROLE_BASE_ANON, .dq_label = &quot;com.apple.main-thread&quot;, .dq_atomic_flags = DQF_THREAD_BOUND | DQF_WIDTH(1), .dq_serialnum = 1,&#125;;#define _dispatch_get_default_queue(overcommit) \\ _dispatch_root_queues[DISPATCH_ROOT_QUEUE_IDX_DEFAULT_QOS + \\ !!(overcommit)]._as_dq 管理队列1234567891011121314151617181920212223242526struct dispatch_queue_global_s _dispatch_mgr_root_queue = &#123; DISPATCH_GLOBAL_OBJECT_HEADER(queue_global), .dq_state = DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE, .do_ctxt = &amp;_dispatch_mgr_root_queue_pthread_context, .dq_label = &quot;com.apple.root.libdispatch-manager&quot;, .dq_atomic_flags = DQF_WIDTH(DISPATCH_QUEUE_WIDTH_POOL), .dq_priority = DISPATCH_PRIORITY_FLAG_MANAGER | DISPATCH_PRIORITY_SATURATED_OVERRIDE, .dq_serialnum = 3, .dgq_thread_pool_size = 1,&#125;;struct dispatch_queue_static_s _dispatch_mgr_q = &#123; DISPATCH_GLOBAL_OBJECT_HEADER(queue_mgr), .dq_state = DISPATCH_QUEUE_STATE_INIT_VALUE(1) | DISPATCH_QUEUE_ROLE_BASE_ANON, .do_ctxt = (void *)-1, .do_targetq = _dispatch_mgr_root_queue._as_dq, .dq_label = &quot;com.apple.libdispatch-manager&quot;, .dq_atomic_flags = DQF_WIDTH(1), .dq_priority = DISPATCH_PRIORITY_FLAG_MANAGER | DISPATCH_PRIORITY_SATURATED_OVERRIDE, .dq_serialnum = 2,&#125;; 可以看到，无论是主队列，管理队列，还是自定义队列，都使用root queue作为target queue Target QueueDarget queue 是队列任务最终执行的地方。但是全局队列没有设置target queue (do_targetq)。同时值得注意的是，targetQueue才是提交的block执行的关键 The target queue determines whether the block will be invoked serially or concurrently with respect to other blocks submitted to that same queue.Serial queues are processed concurrently with respect to each other. QOS在设置队列优先级的时候会涉及到QOS的设置。QOS是自iOS8后新引入的特性。主要包含以下五种： NSQualityOfServiceUserInteractive用户交互相关，通常和UI相关。 NSQualityOfServiceUserInitiated由用户发起且需要立即完成的任务 NSQualityOfServiceUtility需要花费一些时间，不是马上需要结果的任务 NSQualityOfServiceBackground后台任务 NSQualityOfServiceDefault默认优先级，介于NSQualityOfServiceUserInteractive 和 NSQualityOfServiceUtility 之间，在没有QOS信息时默认使用队列优先级和QOS类之间的映射关系如下 1234DISPATCH_QUEUE_PRIORITY_HIGH: QOS_CLASS_USER_INITIATEDDISPATCH_QUEUE_PRIORITY_DEFAULT: QOS_CLASS_DEFAULT DISPATCH_QUEUE_PRIORITY_LOW: QOS_CLASS_UTILITYDISPATCH_QUEUE_PRIORITY_BACKGROUND: QOS_CLASS_BACKGROUND Overcommitovercommit 参数表示队列在执行blokc时，无论多忙都会新开一个线程 The queue will create a new thread for invoking blocks, regardless of how busy the computer is. 在root queue我们也可以看到overcommit的身影。值得注意的是全局队列和自定义并发队列是非overcommit的，而主队列和自定义串行队列的都是overcommit的。当我们使用dispatch_async提交任务到串行队列，由于串行队列一般是overcommit的，所以会创建一个新的线程，而并发队列是非overcommit的，所以不会创建新的线程，而是从底层的线程池中获取。 即便如此，队列在同步执行任务时是不会创建新的线程的，所有的任务都会在当前的线程中执行，且会阻塞线程。dispatch_sync底层使用信号量来实现串行 任务提交我们提交的block任务，经过GCD底层封装之后，被存储于队列的链表中，符合FIFO原则。只有提交到主队列的任务是在主线程中执行，因为其内部线程是和队列绑定的。主队列的任务由Runloop处理，但是分发到其他队列的任务由底层的线程池处理 API深入dispatch_sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167DISPATCH_NOINLINEvoiddispatch_sync(dispatch_queue_t dq, dispatch_block_t work)&#123; uintptr_t dc_flags = DC_FLAG_BLOCK; if (unlikely(_dispatch_block_has_private_data(work))) &#123; return _dispatch_sync_block_with_privdata(dq, work, dc_flags); &#125; _dispatch_sync_f(dq, work, _dispatch_Block_invoke(work), dc_flags);&#125;#endif // __BLOCKS__DISPATCH_NOINLINEstatic void_dispatch_sync_f(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; _dispatch_sync_f_inline(dq, ctxt, func, dc_flags);&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_sync_f_inline(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; // 串行会走到这里 // dispatch queue 的width if (likely(dq-&gt;dq_width == 1)) &#123; return _dispatch_barrier_sync_f(dq, ctxt, func, dc_flags); &#125; // 并发走下面 if (unlikely(dx_metatype(dq) != _DISPATCH_LANE_TYPE)) &#123; DISPATCH_CLIENT_CRASH(0, &quot;Queue type doesn&#x27;t support dispatch_sync&quot;); &#125; dispatch_lane_t dl = upcast(dq)._dl; // 全局并发队列和 绑定了 非派发线程的队列 会走 _dispatch_sync_f_slow // Global concurrent queues and queues bound to non-dispatch threads // always fall into the slow case, see DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE if (unlikely(!_dispatch_queue_try_reserve_sync_width(dl))) &#123; return _dispatch_sync_f_slow(dl, ctxt, func, 0, dl, dc_flags); &#125; // 找到最终的target queue if (unlikely(dq-&gt;do_targetq-&gt;do_targetq)) &#123; return _dispatch_sync_recurse(dl, ctxt, func, dc_flags); &#125; // 开始执行方法 _dispatch_introspection_sync_begin(dl); // 执行block _dispatch_sync_invoke_and_complete(dl, ctxt, func DISPATCH_TRACE_ARG( _dispatch_trace_item_sync_push_pop(dq, ctxt, func, dc_flags)));&#125;DISPATCH_NOINLINEstatic void_dispatch_barrier_sync_f(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; _dispatch_barrier_sync_f_inline(dq, ctxt, func, dc_flags);&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_barrier_sync_f_inline(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; dispatch_tid tid = _dispatch_tid_self(); if (unlikely(dx_metatype(dq) != _DISPATCH_LANE_TYPE)) &#123; DISPATCH_CLIENT_CRASH(0, &quot;Queue type doesn&#x27;t support dispatch_sync&quot;); &#125; dispatch_lane_t dl = upcast(dq)._dl; // The more correct thing to do would be to merge the qos of the thread // that just acquired the barrier lock into the queue state. // // However this is too expensive for the fast path, so skip doing it. // The chosen tradeoff is that if an enqueue on a lower priority thread // contends with this fast path, this thread may receive a useless override. // // Global concurrent queues and queues bound to non-dispatch threads // always fall into the slow case, see DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE if (unlikely(!_dispatch_queue_try_acquire_barrier_sync(dl, tid))) &#123; return _dispatch_sync_f_slow(dl, ctxt, func, DC_FLAG_BARRIER, dl, DC_FLAG_BARRIER | dc_flags); &#125; if (unlikely(dl-&gt;do_targetq-&gt;do_targetq)) &#123; return _dispatch_sync_recurse(dl, ctxt, func, DC_FLAG_BARRIER | dc_flags); &#125; _dispatch_introspection_sync_begin(dl); _dispatch_lane_barrier_sync_invoke_and_complete(dl, ctxt, func DISPATCH_TRACE_ARG(_dispatch_trace_item_sync_push_pop( dq, ctxt, func, dc_flags | DC_FLAG_BARRIER)));&#125;/* * For queues we can cheat and inline the unlock code, which is invalid * for objects with a more complex state machine (sources or mach channels) */ // block执行DISPATCH_NOINLINEstatic void_dispatch_lane_barrier_sync_invoke_and_complete(dispatch_lane_t dq, void *ctxt, dispatch_function_t func DISPATCH_TRACE_ARG(void *dc))&#123; _dispatch_sync_function_invoke_inline(dq, ctxt, func); _dispatch_trace_item_complete(dc); if (unlikely(dq-&gt;dq_items_tail || dq-&gt;dq_width &gt; 1)) &#123; return _dispatch_lane_barrier_complete(dq, 0, 0); &#125; // Presence of any of these bits requires more work that only // _dispatch_*_barrier_complete() handles properly // // Note: testing for RECEIVED_OVERRIDE or RECEIVED_SYNC_WAIT without // checking the role is sloppy, but is a super fast check, and neither of // these bits should be set if the lock was never contended/discovered. const uint64_t fail_unlock_mask = DISPATCH_QUEUE_SUSPEND_BITS_MASK | DISPATCH_QUEUE_ENQUEUED | DISPATCH_QUEUE_DIRTY | DISPATCH_QUEUE_RECEIVED_OVERRIDE | DISPATCH_QUEUE_SYNC_TRANSFER | DISPATCH_QUEUE_RECEIVED_SYNC_WAIT; uint64_t old_state, new_state; // similar to _dispatch_queue_drain_try_unlock os_atomic_rmw_loop2o(dq, dq_state, old_state, new_state, release, &#123; new_state = old_state - DISPATCH_QUEUE_SERIAL_DRAIN_OWNED; new_state &amp;= ~DISPATCH_QUEUE_DRAIN_UNLOCK_MASK; new_state &amp;= ~DISPATCH_QUEUE_MAX_QOS_MASK; if (unlikely(old_state &amp; fail_unlock_mask)) &#123; os_atomic_rmw_loop_give_up(&#123; return _dispatch_lane_barrier_complete(dq, 0, 0); &#125;); &#125; &#125;); if (_dq_state_is_base_wlh(old_state)) &#123; _dispatch_event_loop_assert_not_owned((dispatch_wlh_t)dq); &#125;&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_sync_function_invoke_inline(dispatch_queue_class_t dq, void *ctxt, dispatch_function_t func)&#123; dispatch_thread_frame_s dtf; _dispatch_thread_frame_push(&amp;dtf, dq); _dispatch_client_callout(ctxt, func); _dispatch_perfmon_workitem_inc(); _dispatch_thread_frame_pop(&amp;dtf);&#125; dispatch_async123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253voiddispatch_async(dispatch_queue_t dq, dispatch_block_t work)&#123; dispatch_continuation_t dc = _dispatch_continuation_alloc(); uintptr_t dc_flags = DC_FLAG_CONSUME; dispatch_qos_t qos; qos = _dispatch_continuation_init(dc, dq, work, 0, dc_flags); _dispatch_continuation_async(dq, dc, qos, dc-&gt;dc_flags);&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_continuation_async(dispatch_queue_class_t dqu, dispatch_continuation_t dc, dispatch_qos_t qos, uintptr_t dc_flags)&#123;#if DISPATCH_INTROSPECTION if (!(dc_flags &amp; DC_FLAG_NO_INTROSPECTION)) &#123; _dispatch_trace_item_push(dqu, dc); &#125;#else (void)dc_flags;#endif return dx_push(dqu._dq, dc, qos);&#125;#define dx_push(x, y, z) dx_vtable(x)-&gt;dq_push(x, y, z)// 这里有一系列的实例模版DISPATCH_VTABLE_INSTANCE(queue, // This is the base class for queues, no objects of this type are made .do_type = _DISPATCH_QUEUE_CLUSTER, .do_dispose = _dispatch_object_no_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_object_no_invoke, .dq_activate = _dispatch_queue_no_activate,);DISPATCH_VTABLE_INSTANCE(workloop, .do_type = DISPATCH_WORKLOOP_TYPE, .do_dispose = _dispatch_workloop_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_workloop_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_workloop_wakeup, .dq_push = _dispatch_workloop_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_serial, lane, .do_type = DISPATCH_QUEUE_SERIAL_TYPE, .do_dispose = _dispatch_lane_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_lane_activate, .dq_wakeup = _dispatch_lane_wakeup, .dq_push = _dispatch_lane_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_concurrent, lane, .do_type = DISPATCH_QUEUE_CONCURRENT_TYPE, .do_dispose = _dispatch_lane_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_lane_activate, .dq_wakeup = _dispatch_lane_wakeup, .dq_push = _dispatch_lane_concurrent_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_global, lane, .do_type = DISPATCH_QUEUE_GLOBAL_ROOT_TYPE, .do_dispose = _dispatch_object_no_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_object_no_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_root_queue_wakeup, .dq_push = _dispatch_root_queue_push,);#if DISPATCH_USE_PTHREAD_ROOT_QUEUESDISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_pthread_root, lane, .do_type = DISPATCH_QUEUE_PTHREAD_ROOT_TYPE, .do_dispose = _dispatch_pthread_root_queue_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_object_no_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_root_queue_wakeup, .dq_push = _dispatch_root_queue_push,);#endif // DISPATCH_USE_PTHREAD_ROOT_QUEUESDISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_mgr, lane, .do_type = DISPATCH_QUEUE_MGR_TYPE, .do_dispose = _dispatch_object_no_dispose, .do_debug = _dispatch_queue_debug,#if DISPATCH_USE_MGR_THREAD .do_invoke = _dispatch_mgr_thread,#else .do_invoke = _dispatch_object_no_invoke,#endif .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_mgr_queue_wakeup, .dq_push = _dispatch_mgr_queue_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_main, lane, .do_type = DISPATCH_QUEUE_MAIN_TYPE, .do_dispose = _dispatch_lane_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_main_queue_wakeup, .dq_push = _dispatch_main_queue_push,);#if DISPATCH_COCOA_COMPATDISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_runloop, lane, .do_type = DISPATCH_QUEUE_RUNLOOP_TYPE, .do_dispose = _dispatch_runloop_queue_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_runloop_queue_wakeup, .dq_push = _dispatch_lane_push,);#endifDISPATCH_VTABLE_INSTANCE(source, .do_type = DISPATCH_SOURCE_KEVENT_TYPE, .do_dispose = _dispatch_source_dispose, .do_debug = _dispatch_source_debug, .do_invoke = _dispatch_source_invoke, .dq_activate = _dispatch_source_activate, .dq_wakeup = _dispatch_source_wakeup, .dq_push = _dispatch_lane_push,);DISPATCH_VTABLE_INSTANCE(channel, .do_type = DISPATCH_CHANNEL_TYPE, .do_dispose = _dispatch_channel_dispose, .do_debug = _dispatch_channel_debug, .do_invoke = _dispatch_channel_invoke, .dq_activate = _dispatch_lane_activate, .dq_wakeup = _dispatch_channel_wakeup, .dq_push = _dispatch_lane_push,);#if HAVE_MACHDISPATCH_VTABLE_INSTANCE(mach, .do_type = DISPATCH_MACH_CHANNEL_TYPE, .do_dispose = _dispatch_mach_dispose, .do_debug = _dispatch_mach_debug, .do_invoke = _dispatch_mach_invoke, .dq_activate = _dispatch_mach_activate, .dq_wakeup = _dispatch_mach_wakeup, .dq_push = _dispatch_lane_push,);// 比如 主队列 DISPATCH_NOINLINEvoid_dispatch_main_queue_push(dispatch_queue_main_t dq, dispatch_object_t dou, dispatch_qos_t qos)&#123; // Same as _dispatch_lane_push() but without the refcounting due to being // a global object if (_dispatch_queue_push_item(dq, dou)) &#123; return dx_wakeup(dq, qos, DISPATCH_WAKEUP_MAKE_DIRTY); &#125; qos = _dispatch_queue_push_qos(dq, qos); if (_dispatch_queue_need_override(dq, qos)) &#123; return dx_wakeup(dq, qos, 0); &#125;&#125;// 唤醒runloopvoid_dispatch_main_queue_wakeup(dispatch_queue_main_t dq, dispatch_qos_t qos, dispatch_wakeup_flags_t flags)&#123;#if DISPATCH_COCOA_COMPAT // 线程和队列绑定， 所有主队列走这里 if (_dispatch_queue_is_thread_bound(dq)) &#123; // 唤醒runloop return _dispatch_runloop_queue_wakeup(dq-&gt;_as_dl, qos, flags); &#125;#endif return _dispatch_lane_wakeup(dq, qos, flags);&#125;// 比如全局队列 DISPATCH_NOINLINEvoid_dispatch_root_queue_push(dispatch_queue_global_t rq, dispatch_object_t dou, dispatch_qos_t qos)&#123;#if DISPATCH_USE_KEVENT_WORKQUEUE dispatch_deferred_items_t ddi = _dispatch_deferred_items_get(); if (unlikely(ddi &amp;&amp; ddi-&gt;ddi_can_stash)) &#123; dispatch_object_t old_dou = ddi-&gt;ddi_stashed_dou; dispatch_priority_t rq_overcommit; rq_overcommit = rq-&gt;dq_priority &amp; DISPATCH_PRIORITY_FLAG_OVERCOMMIT; if (likely(!old_dou._do || rq_overcommit)) &#123; dispatch_queue_global_t old_rq = ddi-&gt;ddi_stashed_rq; dispatch_qos_t old_qos = ddi-&gt;ddi_stashed_qos; ddi-&gt;ddi_stashed_rq = rq; ddi-&gt;ddi_stashed_dou = dou; ddi-&gt;ddi_stashed_qos = qos; _dispatch_debug(&quot;deferring item %p, rq %p, qos %d&quot;, dou._do, rq, qos); if (rq_overcommit) &#123; ddi-&gt;ddi_can_stash = false; &#125; if (likely(!old_dou._do)) &#123; return; &#125; // push the previously stashed item qos = old_qos; rq = old_rq; dou = old_dou; &#125; &#125;#endif#if HAVE_PTHREAD_WORKQUEUE_QOS if (_dispatch_root_queue_push_needs_override(rq, qos)) &#123; return _dispatch_root_queue_push_override(rq, dou, qos); &#125;#else (void)qos;#endif _dispatch_root_queue_push_inline(rq, dou, dou, 1);&#125; dispatch_barrierdispatch_oncedispatch_semaphoredispatch_group多线程应用traget queuedispatch_queue_set_specific/dispatch_get_specificdispatch Sourcedispatch Timerdispatch_block_wait/dispatch_block_notifydispatch_group_wait/dispatch_group_notify一些问题死锁场景队列/线程关系及管理模型注意事项相关文献 Threading Programming Guide Concurrency Programming Guide GCD Internals iOS探索 多线程之GCD底层分析 深入理解GCD之dispatch_queue | NeroXie的个人博客 GCD之线程原理向 | 逆水行舟","categories":[],"tags":[{"name":"GCD","slug":"GCD","permalink":"http://deeer.github.io/tags/GCD/"}]}],"categories":[],"tags":[{"name":"GCD","slug":"GCD","permalink":"http://deeer.github.io/tags/GCD/"}]}