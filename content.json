{"meta":{"title":"ğŸ¦– Deeer ğŸ‘¨â€ğŸ’»","subtitle":"å£«ä¸å¯ä»¥ä¸å¼˜æ¯…ï¼Œä»»é‡è€Œé“è¿œã€‚","description":"ä»£ç æ‰‹å·¥è‰ºäºº | Love Linux  | è¿½æ±‚ä½“éªŒ","author":"Deeer","url":"http://deeer.github.io","root":"/"},"pages":[{"title":"about","date":"2015-07-26T08:45:00.000Z","updated":"2020-09-19T12:06:43.000Z","comments":true,"path":"about/index.html","permalink":"http://deeer.github.io/about/index.html","excerpt":"","text":"HEY , THIS IS DEEER."},{"title":"categories","date":"2015-07-26T09:11:08.000Z","updated":"2018-02-27T14:59:45.000Z","comments":true,"path":"categories/index.html","permalink":"http://deeer.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2015-06-02T16:09:09.000Z","updated":"2015-06-06T17:47:06.000Z","comments":true,"path":"tags/index.html","permalink":"http://deeer.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"æ·±å…¥ç†è§£GCD","slug":"æ·±å…¥ç†è§£GCD","date":"2021-03-29T15:06:14.000Z","updated":"2021-04-18T11:27:58.000Z","comments":true,"path":"2021/03/29/æ·±å…¥ç†è§£GCD/","link":"","permalink":"http://deeer.github.io/2021/03/29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3GCD/","excerpt":"é˜Ÿåˆ—åœ¨GCDä¸­åŒ…å«äº†å››ç§é˜Ÿåˆ— ï¼š ä¸»é˜Ÿåˆ—ã€ å…¨å±€é˜Ÿåˆ—ã€ ç®¡ç†é˜Ÿåˆ—ã€è‡ªå®šä¹‰é˜Ÿåˆ—ã€‚è¿™é‡Œæˆ‘ä»¬ä¸€ä¸€æ¥çœ‹ï¼Œå…¶ä¸­çš„å®ç°é€»è¾‘ã€‚","text":"é˜Ÿåˆ—åœ¨GCDä¸­åŒ…å«äº†å››ç§é˜Ÿåˆ— ï¼š ä¸»é˜Ÿåˆ—ã€ å…¨å±€é˜Ÿåˆ—ã€ ç®¡ç†é˜Ÿåˆ—ã€è‡ªå®šä¹‰é˜Ÿåˆ—ã€‚è¿™é‡Œæˆ‘ä»¬ä¸€ä¸€æ¥çœ‹ï¼Œå…¶ä¸­çš„å®ç°é€»è¾‘ã€‚ è‡ªå®šä¹‰é˜Ÿåˆ—é˜Ÿåˆ—åº•å±‚ä½¿ç”¨dispatch_queue_createè¿›è¡Œåˆ›å»º 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161dispatch_queue_tdispatch_queue_create(const char *label, dispatch_queue_attr_t attr)&#123; return _dispatch_lane_create_with_target(label, attr, DISPATCH_TARGET_QUEUE_DEFAULT, true);&#125;----------------------------------------// dispatch_queue_t tq ç›®æ ‡é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—ä¸­å®é™…çš„ä»»åŠ¡åœ¨target queue ä¸­æ‰§è¡Œï¼Œè¿™é‡Œé»˜è®¤ä¼  DISPATCH_TARGET_QUEUE_DEFAULT - NULL// dispatch_queue_attr_t é˜Ÿåˆ—å±æ€§ // ä»å‚æ•°ä¸­è·å–qoså±æ€§DISPATCH_NOINLINEstatic dispatch_queue_t_dispatch_lane_create_with_target(const char *label, dispatch_queue_attr_t dqa, dispatch_queue_t tq, bool legacy)&#123; // è·å–é˜Ÿåˆ—å±æ€§ä¿¡æ¯ // dispatch_queue_attr_info_s // typedef struct dispatch_queue_attr_info_s &#123; // dispatch_qos_t dqai_qos : 8; // int dqai_relpri : 8; // uint16_t dqai_overcommit:2; // uint16_t dqai_autorelease_frequency:2; // uint16_t dqai_concurrent:1; // uint16_t dqai_inactive:1; // &#125; dispatch_queue_attr_info_t; dispatch_queue_attr_info_t dqai = _dispatch_queue_attr_to_info(dqa); // // Step 1: Normalize arguments (qos, overcommit, tq) // // è·å–é˜Ÿåˆ—çš„qosä¿¡æ¯ dispatch_qos_t qos = dqai.dqai_qos; //#if !HAVE_PTHREAD_WORKQUEUE_QOS if (qos == DISPATCH_QOS_USER_INTERACTIVE) &#123; dqai.dqai_qos = qos = DISPATCH_QOS_USER_INITIATED; &#125; if (qos == DISPATCH_QOS_MAINTENANCE) &#123; dqai.dqai_qos = qos = DISPATCH_QOS_BACKGROUND; &#125;#endif // !HAVE_PTHREAD_WORKQUEUE_QOS // overcommitä¿¡æ¯ _dispatch_queue_attr_overcommit_t overcommit = dqai.dqai_overcommit; // å¦‚æœæ²¡æœ‰overcommitä¿¡æ¯ ä¸” æœ‰ targetqueue if (overcommit != _dispatch_queue_attr_overcommit_unspecified &amp;&amp; tq) &#123; // ä¸èƒ½åŒæ—¶æŒ‡å®š overcommit ä¿¡æ¯ å’Œ éå…¨å±€targetqueue if (tq-&gt;do_targetq) &#123; DISPATCH_CLIENT_CRASH(tq, &quot;Cannot specify both overcommit and &quot; &quot;a non-global target queue&quot;); &#125; &#125; if (tq &amp;&amp; dx_type(tq) == DISPATCH_QUEUE_GLOBAL_ROOT_TYPE) &#123; // Handle discrepancies between attr and target queue, attributes win if (overcommit == _dispatch_queue_attr_overcommit_unspecified) &#123; if (tq-&gt;dq_priority &amp; DISPATCH_PRIORITY_FLAG_OVERCOMMIT) &#123; overcommit = _dispatch_queue_attr_overcommit_enabled; &#125; else &#123; overcommit = _dispatch_queue_attr_overcommit_disabled; &#125; &#125; if (qos == DISPATCH_QOS_UNSPECIFIED) &#123; qos = _dispatch_priority_qos(tq-&gt;dq_priority); &#125; tq = NULL; &#125; else if (tq &amp;&amp; !tq-&gt;do_targetq) &#123; // target æ˜¯ pthread æˆ–è€…runloopçš„root queue ï¼Œè®¾ç½®QOS æˆ–è€… overcommit æ˜¯ä¸å…è®¸çš„ // target is a pthread or runloop root queue, setting QoS or overcommit // is disallowed if (overcommit != _dispatch_queue_attr_overcommit_unspecified) &#123; DISPATCH_CLIENT_CRASH(tq, &quot;Cannot specify an overcommit attribute &quot; &quot;and use this kind of target queue&quot;); &#125; &#125; else &#123; if (overcommit == _dispatch_queue_attr_overcommit_unspecified) &#123; // Serial queues default to overcommit! // ä¸²è¡Œé˜Ÿåˆ—çš„overcommit æ˜¯ å¯ç”¨çš„ overcommit = dqai.dqai_concurrent ? _dispatch_queue_attr_overcommit_disabled : _dispatch_queue_attr_overcommit_enabled; &#125; &#125; // å¦‚æœæ²¡æœ‰target queueï¼Œ è®¾ç½®è·å–ä»root queue ä¸­å»è·å– if (!tq) &#123; // è·å–root queue tq = _dispatch_get_root_queue( qos == DISPATCH_QOS_UNSPECIFIED ? DISPATCH_QOS_DEFAULT : qos, overcommit == _dispatch_queue_attr_overcommit_enabled)-&gt;_as_dq; if (unlikely(!tq)) &#123; DISPATCH_CLIENT_CRASH(qos, &quot;Invalid queue attribute&quot;); &#125; &#125; // // Step 2: Initialize the queue // if (legacy) &#123; // if any of these attributes is specified, use non legacy classes if (dqai.dqai_inactive || dqai.dqai_autorelease_frequency) &#123; legacy = false; &#125; &#125; const void *vtable; dispatch_queue_flags_t dqf = legacy ? DQF_MUTABLE : 0; // if (dqai.dqai_concurrent) &#123; vtable = DISPATCH_VTABLE(queue_concurrent); &#125; else &#123; vtable = DISPATCH_VTABLE(queue_serial); &#125; // auto relase switch (dqai.dqai_autorelease_frequency) &#123; case DISPATCH_AUTORELEASE_FREQUENCY_NEVER: dqf |= DQF_AUTORELEASE_NEVER; break; case DISPATCH_AUTORELEASE_FREQUENCY_WORK_ITEM: dqf |= DQF_AUTORELEASE_ALWAYS; break; &#125; if (label) &#123; const char *tmp = _dispatch_strdup_if_mutable(label); if (tmp != label) &#123; dqf |= DQF_LABEL_NEEDS_FREE; label = tmp; &#125; &#125; dispatch_lane_t dq = _dispatch_object_alloc(vtable, sizeof(struct dispatch_lane_s)); _dispatch_queue_init(dq, dqf, dqai.dqai_concurrent ? DISPATCH_QUEUE_WIDTH_MAX : 1, DISPATCH_QUEUE_ROLE_INNER | (dqai.dqai_inactive ? DISPATCH_QUEUE_INACTIVE : 0)); dq-&gt;dq_label = label; dq-&gt;dq_priority = _dispatch_priority_make((dispatch_qos_t)dqai.dqai_qos, dqai.dqai_relpri); if (overcommit == _dispatch_queue_attr_overcommit_enabled) &#123; dq-&gt;dq_priority |= DISPATCH_PRIORITY_FLAG_OVERCOMMIT; &#125; if (!dqai.dqai_inactive) &#123; // ä»target ç»§æ‰¿ä¼˜å…ˆçº§ _dispatch_queue_priority_inherit_from_target(dq, tq); _dispatch_lane_inherit_wlh_from_target(dq, tq); &#125; _dispatch_retain(tq); dq-&gt;do_targetq = tq; _dispatch_object_debug(dq, &quot;%s&quot;, __func__); return _dispatch_trace_queue_create(dq)._dq;&#125; å…¨å±€é˜Ÿåˆ— - dispatch_get_global_queue1234567891011121314151617181920212223dispatch_queue_global_tdispatch_get_global_queue(long priority, unsigned long flags)&#123; dispatch_assert(countof(_dispatch_root_queues) == DISPATCH_ROOT_QUEUE_COUNT); if (flags &amp; ~(unsigned long)DISPATCH_QUEUE_OVERCOMMIT) &#123; return DISPATCH_BAD_INPUT; &#125; dispatch_qos_t qos = _dispatch_qos_from_queue_priority(priority);#if !HAVE_PTHREAD_WORKQUEUE_QOS if (qos == QOS_CLASS_MAINTENANCE) &#123; qos = DISPATCH_QOS_BACKGROUND; &#125; else if (qos == QOS_CLASS_USER_INTERACTIVE) &#123; qos = DISPATCH_QOS_USER_INITIATED; &#125;#endif if (qos == DISPATCH_QOS_UNSPECIFIED) &#123; return DISPATCH_BAD_INPUT; &#125; return _dispatch_get_root_queue(qos, flags &amp; DISPATCH_QUEUE_OVERCOMMIT);&#125; è¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å…¨å±€é˜Ÿåˆ—æœ€ç»ˆè°ƒç”¨çš„æ˜¯_dispatch_get_root_queue 123456789DISPATCH_ALWAYS_INLINE DISPATCH_CONSTstatic inline dispatch_queue_global_t_dispatch_get_root_queue(dispatch_qos_t qos, bool overcommit)&#123; if (unlikely(qos &lt; DISPATCH_QOS_MIN || qos &gt; DISPATCH_QOS_MAX)) &#123; DISPATCH_CLIENT_CRASH(qos, &quot;Corrupted priority&quot;); &#125; return &amp;_dispatch_root_queues[2 * (qos - 1) + overcommit];&#125; å®é™…ä¸Š_dispatch_root_queuessæ˜¯ä¸€ä¸ªç³»ç»Ÿç¡¬ç¼–ç çš„é˜Ÿåˆ—æ•°ç»„ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667struct dispatch_queue_global_s _dispatch_root_queues[] = &#123;#define _DISPATCH_ROOT_QUEUE_IDX(n, flags) \\ ((flags &amp; DISPATCH_PRIORITY_FLAG_OVERCOMMIT) ? \\ DISPATCH_ROOT_QUEUE_IDX_##n##_QOS_OVERCOMMIT : \\ DISPATCH_ROOT_QUEUE_IDX_##n##_QOS)#define _DISPATCH_ROOT_QUEUE_ENTRY(n, flags, ...) \\ [_DISPATCH_ROOT_QUEUE_IDX(n, flags)] = &#123; \\ DISPATCH_GLOBAL_OBJECT_HEADER(queue_global), \\ .dq_state = DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE, \\ .do_ctxt = _dispatch_root_queue_ctxt(_DISPATCH_ROOT_QUEUE_IDX(n, flags)), \\ .dq_atomic_flags = DQF_WIDTH(DISPATCH_QUEUE_WIDTH_POOL), \\ .dq_priority = flags | ((flags &amp; DISPATCH_PRIORITY_FLAG_FALLBACK) ? \\ _dispatch_priority_make_fallback(DISPATCH_QOS_##n) : \\ _dispatch_priority_make(DISPATCH_QOS_##n, 0)), \\ __VA_ARGS__ \\ &#125; _DISPATCH_ROOT_QUEUE_ENTRY(MAINTENANCE, 0, .dq_label = &quot;com.apple.root.maintenance-qos&quot;, .dq_serialnum = 4, ), _DISPATCH_ROOT_QUEUE_ENTRY(MAINTENANCE, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.maintenance-qos.overcommit&quot;, .dq_serialnum = 5, ), _DISPATCH_ROOT_QUEUE_ENTRY(BACKGROUND, 0, .dq_label = &quot;com.apple.root.background-qos&quot;, .dq_serialnum = 6, ), _DISPATCH_ROOT_QUEUE_ENTRY(BACKGROUND, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.background-qos.overcommit&quot;, .dq_serialnum = 7, ), _DISPATCH_ROOT_QUEUE_ENTRY(UTILITY, 0, .dq_label = &quot;com.apple.root.utility-qos&quot;, .dq_serialnum = 8, ), _DISPATCH_ROOT_QUEUE_ENTRY(UTILITY, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.utility-qos.overcommit&quot;, .dq_serialnum = 9, ), _DISPATCH_ROOT_QUEUE_ENTRY(DEFAULT, DISPATCH_PRIORITY_FLAG_FALLBACK, .dq_label = &quot;com.apple.root.default-qos&quot;, .dq_serialnum = 10, ), _DISPATCH_ROOT_QUEUE_ENTRY(DEFAULT, DISPATCH_PRIORITY_FLAG_FALLBACK | DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.default-qos.overcommit&quot;, .dq_serialnum = 11, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INITIATED, 0, .dq_label = &quot;com.apple.root.user-initiated-qos&quot;, .dq_serialnum = 12, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INITIATED, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.user-initiated-qos.overcommit&quot;, .dq_serialnum = 13, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INTERACTIVE, 0, .dq_label = &quot;com.apple.root.user-interactive-qos&quot;, .dq_serialnum = 14, ), _DISPATCH_ROOT_QUEUE_ENTRY(USER_INTERACTIVE, DISPATCH_PRIORITY_FLAG_OVERCOMMIT, .dq_label = &quot;com.apple.root.user-interactive-qos.overcommit&quot;, .dq_serialnum = 15, ),&#125;; ä¸»é˜Ÿåˆ—123456789101112131415struct dispatch_queue_static_s _dispatch_main_q = &#123; DISPATCH_GLOBAL_OBJECT_HEADER(queue_main),#if !DISPATCH_USE_RESOLVERS .do_targetq = _dispatch_get_default_queue(true),#endif .dq_state = DISPATCH_QUEUE_STATE_INIT_VALUE(1) | DISPATCH_QUEUE_ROLE_BASE_ANON, .dq_label = &quot;com.apple.main-thread&quot;, .dq_atomic_flags = DQF_THREAD_BOUND | DQF_WIDTH(1), .dq_serialnum = 1,&#125;;#define _dispatch_get_default_queue(overcommit) \\ _dispatch_root_queues[DISPATCH_ROOT_QUEUE_IDX_DEFAULT_QOS + \\ !!(overcommit)]._as_dq ç®¡ç†é˜Ÿåˆ—1234567891011121314151617181920212223242526struct dispatch_queue_global_s _dispatch_mgr_root_queue = &#123; DISPATCH_GLOBAL_OBJECT_HEADER(queue_global), .dq_state = DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE, .do_ctxt = &amp;_dispatch_mgr_root_queue_pthread_context, .dq_label = &quot;com.apple.root.libdispatch-manager&quot;, .dq_atomic_flags = DQF_WIDTH(DISPATCH_QUEUE_WIDTH_POOL), .dq_priority = DISPATCH_PRIORITY_FLAG_MANAGER | DISPATCH_PRIORITY_SATURATED_OVERRIDE, .dq_serialnum = 3, .dgq_thread_pool_size = 1,&#125;;struct dispatch_queue_static_s _dispatch_mgr_q = &#123; DISPATCH_GLOBAL_OBJECT_HEADER(queue_mgr), .dq_state = DISPATCH_QUEUE_STATE_INIT_VALUE(1) | DISPATCH_QUEUE_ROLE_BASE_ANON, .do_ctxt = (void *)-1, .do_targetq = _dispatch_mgr_root_queue._as_dq, .dq_label = &quot;com.apple.libdispatch-manager&quot;, .dq_atomic_flags = DQF_WIDTH(1), .dq_priority = DISPATCH_PRIORITY_FLAG_MANAGER | DISPATCH_PRIORITY_SATURATED_OVERRIDE, .dq_serialnum = 2,&#125;; å¯ä»¥çœ‹åˆ°ï¼Œæ— è®ºæ˜¯ä¸»é˜Ÿåˆ—ï¼Œç®¡ç†é˜Ÿåˆ—ï¼Œè¿˜æ˜¯è‡ªå®šä¹‰é˜Ÿåˆ—ï¼Œéƒ½ä½¿ç”¨root queueä½œä¸ºtarget queue Target QueueDarget queue æ˜¯é˜Ÿåˆ—ä»»åŠ¡æœ€ç»ˆæ‰§è¡Œçš„åœ°æ–¹ã€‚ä½†æ˜¯å…¨å±€é˜Ÿåˆ—æ²¡æœ‰è®¾ç½®target queue (do_targetq)ã€‚åŒæ—¶å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒtargetQueueæ‰æ˜¯æäº¤çš„blockæ‰§è¡Œçš„å…³é”® The target queue determines whether the block will be invoked serially or concurrently with respect to other blocks submitted to that same queue.Serial queues are processed concurrently with respect to each other. QOSåœ¨è®¾ç½®é˜Ÿåˆ—ä¼˜å…ˆçº§çš„æ—¶å€™ä¼šæ¶‰åŠåˆ°QOSçš„è®¾ç½®ã€‚QOSæ˜¯è‡ªiOS8åæ–°å¼•å…¥çš„ç‰¹æ€§ã€‚ä¸»è¦åŒ…å«ä»¥ä¸‹äº”ç§ï¼š NSQualityOfServiceUserInteractiveç”¨æˆ·äº¤äº’ç›¸å…³ï¼Œé€šå¸¸å’ŒUIç›¸å…³ã€‚ NSQualityOfServiceUserInitiatedç”±ç”¨æˆ·å‘èµ·ä¸”éœ€è¦ç«‹å³å®Œæˆçš„ä»»åŠ¡ NSQualityOfServiceUtilityéœ€è¦èŠ±è´¹ä¸€äº›æ—¶é—´ï¼Œä¸æ˜¯é©¬ä¸Šéœ€è¦ç»“æœçš„ä»»åŠ¡ NSQualityOfServiceBackgroundåå°ä»»åŠ¡ NSQualityOfServiceDefaulté»˜è®¤ä¼˜å…ˆçº§ï¼Œä»‹äºNSQualityOfServiceUserInteractive å’Œ NSQualityOfServiceUtility ä¹‹é—´ï¼Œåœ¨æ²¡æœ‰QOSä¿¡æ¯æ—¶é»˜è®¤ä½¿ç”¨é˜Ÿåˆ—ä¼˜å…ˆçº§å’ŒQOSç±»ä¹‹é—´çš„æ˜ å°„å…³ç³»å¦‚ä¸‹ 1234DISPATCH_QUEUE_PRIORITY_HIGH: QOS_CLASS_USER_INITIATEDDISPATCH_QUEUE_PRIORITY_DEFAULT: QOS_CLASS_DEFAULT DISPATCH_QUEUE_PRIORITY_LOW: QOS_CLASS_UTILITYDISPATCH_QUEUE_PRIORITY_BACKGROUND: QOS_CLASS_BACKGROUND Overcommitovercommit å‚æ•°è¡¨ç¤ºé˜Ÿåˆ—åœ¨æ‰§è¡Œblokcæ—¶ï¼Œæ— è®ºå¤šå¿™éƒ½ä¼šæ–°å¼€ä¸€ä¸ªçº¿ç¨‹ The queue will create a new thread for invoking blocks, regardless of how busy the computer is. åœ¨root queueæˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°overcommitçš„èº«å½±ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯å…¨å±€é˜Ÿåˆ—å’Œè‡ªå®šä¹‰å¹¶å‘é˜Ÿåˆ—æ˜¯éovercommitçš„ï¼Œè€Œä¸»é˜Ÿåˆ—å’Œè‡ªå®šä¹‰ä¸²è¡Œé˜Ÿåˆ—çš„éƒ½æ˜¯overcommitçš„ã€‚å½“æˆ‘ä»¬ä½¿ç”¨dispatch_asyncæäº¤ä»»åŠ¡åˆ°ä¸²è¡Œé˜Ÿåˆ—ï¼Œç”±äºä¸²è¡Œé˜Ÿåˆ—ä¸€èˆ¬æ˜¯overcommitçš„ï¼Œæ‰€ä»¥ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„çº¿ç¨‹ï¼Œè€Œå¹¶å‘é˜Ÿåˆ—æ˜¯éovercommitçš„ï¼Œæ‰€ä»¥ä¸ä¼šåˆ›å»ºæ–°çš„çº¿ç¨‹ï¼Œè€Œæ˜¯ä»åº•å±‚çš„çº¿ç¨‹æ± ä¸­è·å–ã€‚ å³ä¾¿å¦‚æ­¤ï¼Œé˜Ÿåˆ—åœ¨åŒæ­¥æ‰§è¡Œä»»åŠ¡æ—¶æ˜¯ä¸ä¼šåˆ›å»ºæ–°çš„çº¿ç¨‹çš„ï¼Œæ‰€æœ‰çš„ä»»åŠ¡éƒ½ä¼šåœ¨å½“å‰çš„çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œä¸”ä¼šé˜»å¡çº¿ç¨‹ã€‚dispatch_syncåº•å±‚ä½¿ç”¨ä¿¡å·é‡æ¥å®ç°ä¸²è¡Œ ä»»åŠ¡æäº¤æˆ‘ä»¬æäº¤çš„blockä»»åŠ¡ï¼Œç»è¿‡GCDåº•å±‚å°è£…ä¹‹åï¼Œè¢«å­˜å‚¨äºé˜Ÿåˆ—çš„é“¾è¡¨ä¸­ï¼Œç¬¦åˆFIFOåŸåˆ™ã€‚åªæœ‰æäº¤åˆ°ä¸»é˜Ÿåˆ—çš„ä»»åŠ¡æ˜¯åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œå› ä¸ºå…¶å†…éƒ¨çº¿ç¨‹æ˜¯å’Œé˜Ÿåˆ—ç»‘å®šçš„ã€‚ä¸»é˜Ÿåˆ—çš„ä»»åŠ¡ç”±Runloopå¤„ç†ï¼Œä½†æ˜¯åˆ†å‘åˆ°å…¶ä»–é˜Ÿåˆ—çš„ä»»åŠ¡ç”±åº•å±‚çš„çº¿ç¨‹æ± å¤„ç† APIæ·±å…¥dispatch_sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167DISPATCH_NOINLINEvoiddispatch_sync(dispatch_queue_t dq, dispatch_block_t work)&#123; uintptr_t dc_flags = DC_FLAG_BLOCK; if (unlikely(_dispatch_block_has_private_data(work))) &#123; return _dispatch_sync_block_with_privdata(dq, work, dc_flags); &#125; _dispatch_sync_f(dq, work, _dispatch_Block_invoke(work), dc_flags);&#125;#endif // __BLOCKS__DISPATCH_NOINLINEstatic void_dispatch_sync_f(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; _dispatch_sync_f_inline(dq, ctxt, func, dc_flags);&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_sync_f_inline(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; // ä¸²è¡Œä¼šèµ°åˆ°è¿™é‡Œ // dispatch queue çš„width if (likely(dq-&gt;dq_width == 1)) &#123; return _dispatch_barrier_sync_f(dq, ctxt, func, dc_flags); &#125; // å¹¶å‘èµ°ä¸‹é¢ if (unlikely(dx_metatype(dq) != _DISPATCH_LANE_TYPE)) &#123; DISPATCH_CLIENT_CRASH(0, &quot;Queue type doesn&#x27;t support dispatch_sync&quot;); &#125; dispatch_lane_t dl = upcast(dq)._dl; // å…¨å±€å¹¶å‘é˜Ÿåˆ—å’Œ ç»‘å®šäº† éæ´¾å‘çº¿ç¨‹çš„é˜Ÿåˆ— ä¼šèµ° _dispatch_sync_f_slow // Global concurrent queues and queues bound to non-dispatch threads // always fall into the slow case, see DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE if (unlikely(!_dispatch_queue_try_reserve_sync_width(dl))) &#123; return _dispatch_sync_f_slow(dl, ctxt, func, 0, dl, dc_flags); &#125; // æ‰¾åˆ°æœ€ç»ˆçš„target queue if (unlikely(dq-&gt;do_targetq-&gt;do_targetq)) &#123; return _dispatch_sync_recurse(dl, ctxt, func, dc_flags); &#125; // å¼€å§‹æ‰§è¡Œæ–¹æ³• _dispatch_introspection_sync_begin(dl); // æ‰§è¡Œblock _dispatch_sync_invoke_and_complete(dl, ctxt, func DISPATCH_TRACE_ARG( _dispatch_trace_item_sync_push_pop(dq, ctxt, func, dc_flags)));&#125;DISPATCH_NOINLINEstatic void_dispatch_barrier_sync_f(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; _dispatch_barrier_sync_f_inline(dq, ctxt, func, dc_flags);&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_barrier_sync_f_inline(dispatch_queue_t dq, void *ctxt, dispatch_function_t func, uintptr_t dc_flags)&#123; dispatch_tid tid = _dispatch_tid_self(); if (unlikely(dx_metatype(dq) != _DISPATCH_LANE_TYPE)) &#123; DISPATCH_CLIENT_CRASH(0, &quot;Queue type doesn&#x27;t support dispatch_sync&quot;); &#125; dispatch_lane_t dl = upcast(dq)._dl; // The more correct thing to do would be to merge the qos of the thread // that just acquired the barrier lock into the queue state. // // However this is too expensive for the fast path, so skip doing it. // The chosen tradeoff is that if an enqueue on a lower priority thread // contends with this fast path, this thread may receive a useless override. // // Global concurrent queues and queues bound to non-dispatch threads // always fall into the slow case, see DISPATCH_ROOT_QUEUE_STATE_INIT_VALUE if (unlikely(!_dispatch_queue_try_acquire_barrier_sync(dl, tid))) &#123; return _dispatch_sync_f_slow(dl, ctxt, func, DC_FLAG_BARRIER, dl, DC_FLAG_BARRIER | dc_flags); &#125; if (unlikely(dl-&gt;do_targetq-&gt;do_targetq)) &#123; return _dispatch_sync_recurse(dl, ctxt, func, DC_FLAG_BARRIER | dc_flags); &#125; _dispatch_introspection_sync_begin(dl); _dispatch_lane_barrier_sync_invoke_and_complete(dl, ctxt, func DISPATCH_TRACE_ARG(_dispatch_trace_item_sync_push_pop( dq, ctxt, func, dc_flags | DC_FLAG_BARRIER)));&#125;/* * For queues we can cheat and inline the unlock code, which is invalid * for objects with a more complex state machine (sources or mach channels) */ // blockæ‰§è¡ŒDISPATCH_NOINLINEstatic void_dispatch_lane_barrier_sync_invoke_and_complete(dispatch_lane_t dq, void *ctxt, dispatch_function_t func DISPATCH_TRACE_ARG(void *dc))&#123; _dispatch_sync_function_invoke_inline(dq, ctxt, func); _dispatch_trace_item_complete(dc); if (unlikely(dq-&gt;dq_items_tail || dq-&gt;dq_width &gt; 1)) &#123; return _dispatch_lane_barrier_complete(dq, 0, 0); &#125; // Presence of any of these bits requires more work that only // _dispatch_*_barrier_complete() handles properly // // Note: testing for RECEIVED_OVERRIDE or RECEIVED_SYNC_WAIT without // checking the role is sloppy, but is a super fast check, and neither of // these bits should be set if the lock was never contended/discovered. const uint64_t fail_unlock_mask = DISPATCH_QUEUE_SUSPEND_BITS_MASK | DISPATCH_QUEUE_ENQUEUED | DISPATCH_QUEUE_DIRTY | DISPATCH_QUEUE_RECEIVED_OVERRIDE | DISPATCH_QUEUE_SYNC_TRANSFER | DISPATCH_QUEUE_RECEIVED_SYNC_WAIT; uint64_t old_state, new_state; // similar to _dispatch_queue_drain_try_unlock os_atomic_rmw_loop2o(dq, dq_state, old_state, new_state, release, &#123; new_state = old_state - DISPATCH_QUEUE_SERIAL_DRAIN_OWNED; new_state &amp;= ~DISPATCH_QUEUE_DRAIN_UNLOCK_MASK; new_state &amp;= ~DISPATCH_QUEUE_MAX_QOS_MASK; if (unlikely(old_state &amp; fail_unlock_mask)) &#123; os_atomic_rmw_loop_give_up(&#123; return _dispatch_lane_barrier_complete(dq, 0, 0); &#125;); &#125; &#125;); if (_dq_state_is_base_wlh(old_state)) &#123; _dispatch_event_loop_assert_not_owned((dispatch_wlh_t)dq); &#125;&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_sync_function_invoke_inline(dispatch_queue_class_t dq, void *ctxt, dispatch_function_t func)&#123; dispatch_thread_frame_s dtf; _dispatch_thread_frame_push(&amp;dtf, dq); _dispatch_client_callout(ctxt, func); _dispatch_perfmon_workitem_inc(); _dispatch_thread_frame_pop(&amp;dtf);&#125; dispatch_async123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253voiddispatch_async(dispatch_queue_t dq, dispatch_block_t work)&#123; dispatch_continuation_t dc = _dispatch_continuation_alloc(); uintptr_t dc_flags = DC_FLAG_CONSUME; dispatch_qos_t qos; qos = _dispatch_continuation_init(dc, dq, work, 0, dc_flags); _dispatch_continuation_async(dq, dc, qos, dc-&gt;dc_flags);&#125;DISPATCH_ALWAYS_INLINEstatic inline void_dispatch_continuation_async(dispatch_queue_class_t dqu, dispatch_continuation_t dc, dispatch_qos_t qos, uintptr_t dc_flags)&#123;#if DISPATCH_INTROSPECTION if (!(dc_flags &amp; DC_FLAG_NO_INTROSPECTION)) &#123; _dispatch_trace_item_push(dqu, dc); &#125;#else (void)dc_flags;#endif return dx_push(dqu._dq, dc, qos);&#125;#define dx_push(x, y, z) dx_vtable(x)-&gt;dq_push(x, y, z)// è¿™é‡Œæœ‰ä¸€ç³»åˆ—çš„å®ä¾‹æ¨¡ç‰ˆDISPATCH_VTABLE_INSTANCE(queue, // This is the base class for queues, no objects of this type are made .do_type = _DISPATCH_QUEUE_CLUSTER, .do_dispose = _dispatch_object_no_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_object_no_invoke, .dq_activate = _dispatch_queue_no_activate,);DISPATCH_VTABLE_INSTANCE(workloop, .do_type = DISPATCH_WORKLOOP_TYPE, .do_dispose = _dispatch_workloop_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_workloop_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_workloop_wakeup, .dq_push = _dispatch_workloop_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_serial, lane, .do_type = DISPATCH_QUEUE_SERIAL_TYPE, .do_dispose = _dispatch_lane_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_lane_activate, .dq_wakeup = _dispatch_lane_wakeup, .dq_push = _dispatch_lane_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_concurrent, lane, .do_type = DISPATCH_QUEUE_CONCURRENT_TYPE, .do_dispose = _dispatch_lane_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_lane_activate, .dq_wakeup = _dispatch_lane_wakeup, .dq_push = _dispatch_lane_concurrent_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_global, lane, .do_type = DISPATCH_QUEUE_GLOBAL_ROOT_TYPE, .do_dispose = _dispatch_object_no_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_object_no_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_root_queue_wakeup, .dq_push = _dispatch_root_queue_push,);#if DISPATCH_USE_PTHREAD_ROOT_QUEUESDISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_pthread_root, lane, .do_type = DISPATCH_QUEUE_PTHREAD_ROOT_TYPE, .do_dispose = _dispatch_pthread_root_queue_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_object_no_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_root_queue_wakeup, .dq_push = _dispatch_root_queue_push,);#endif // DISPATCH_USE_PTHREAD_ROOT_QUEUESDISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_mgr, lane, .do_type = DISPATCH_QUEUE_MGR_TYPE, .do_dispose = _dispatch_object_no_dispose, .do_debug = _dispatch_queue_debug,#if DISPATCH_USE_MGR_THREAD .do_invoke = _dispatch_mgr_thread,#else .do_invoke = _dispatch_object_no_invoke,#endif .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_mgr_queue_wakeup, .dq_push = _dispatch_mgr_queue_push,);DISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_main, lane, .do_type = DISPATCH_QUEUE_MAIN_TYPE, .do_dispose = _dispatch_lane_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_main_queue_wakeup, .dq_push = _dispatch_main_queue_push,);#if DISPATCH_COCOA_COMPATDISPATCH_VTABLE_SUBCLASS_INSTANCE(queue_runloop, lane, .do_type = DISPATCH_QUEUE_RUNLOOP_TYPE, .do_dispose = _dispatch_runloop_queue_dispose, .do_debug = _dispatch_queue_debug, .do_invoke = _dispatch_lane_invoke, .dq_activate = _dispatch_queue_no_activate, .dq_wakeup = _dispatch_runloop_queue_wakeup, .dq_push = _dispatch_lane_push,);#endifDISPATCH_VTABLE_INSTANCE(source, .do_type = DISPATCH_SOURCE_KEVENT_TYPE, .do_dispose = _dispatch_source_dispose, .do_debug = _dispatch_source_debug, .do_invoke = _dispatch_source_invoke, .dq_activate = _dispatch_source_activate, .dq_wakeup = _dispatch_source_wakeup, .dq_push = _dispatch_lane_push,);DISPATCH_VTABLE_INSTANCE(channel, .do_type = DISPATCH_CHANNEL_TYPE, .do_dispose = _dispatch_channel_dispose, .do_debug = _dispatch_channel_debug, .do_invoke = _dispatch_channel_invoke, .dq_activate = _dispatch_lane_activate, .dq_wakeup = _dispatch_channel_wakeup, .dq_push = _dispatch_lane_push,);#if HAVE_MACHDISPATCH_VTABLE_INSTANCE(mach, .do_type = DISPATCH_MACH_CHANNEL_TYPE, .do_dispose = _dispatch_mach_dispose, .do_debug = _dispatch_mach_debug, .do_invoke = _dispatch_mach_invoke, .dq_activate = _dispatch_mach_activate, .dq_wakeup = _dispatch_mach_wakeup, .dq_push = _dispatch_lane_push,);// æ¯”å¦‚ ä¸»é˜Ÿåˆ— DISPATCH_NOINLINEvoid_dispatch_main_queue_push(dispatch_queue_main_t dq, dispatch_object_t dou, dispatch_qos_t qos)&#123; // Same as _dispatch_lane_push() but without the refcounting due to being // a global object if (_dispatch_queue_push_item(dq, dou)) &#123; return dx_wakeup(dq, qos, DISPATCH_WAKEUP_MAKE_DIRTY); &#125; qos = _dispatch_queue_push_qos(dq, qos); if (_dispatch_queue_need_override(dq, qos)) &#123; return dx_wakeup(dq, qos, 0); &#125;&#125;// å”¤é†’runloopvoid_dispatch_main_queue_wakeup(dispatch_queue_main_t dq, dispatch_qos_t qos, dispatch_wakeup_flags_t flags)&#123;#if DISPATCH_COCOA_COMPAT // çº¿ç¨‹å’Œé˜Ÿåˆ—ç»‘å®šï¼Œ æ‰€æœ‰ä¸»é˜Ÿåˆ—èµ°è¿™é‡Œ if (_dispatch_queue_is_thread_bound(dq)) &#123; // å”¤é†’runloop return _dispatch_runloop_queue_wakeup(dq-&gt;_as_dl, qos, flags); &#125;#endif return _dispatch_lane_wakeup(dq, qos, flags);&#125;// æ¯”å¦‚å…¨å±€é˜Ÿåˆ— DISPATCH_NOINLINEvoid_dispatch_root_queue_push(dispatch_queue_global_t rq, dispatch_object_t dou, dispatch_qos_t qos)&#123;#if DISPATCH_USE_KEVENT_WORKQUEUE dispatch_deferred_items_t ddi = _dispatch_deferred_items_get(); if (unlikely(ddi &amp;&amp; ddi-&gt;ddi_can_stash)) &#123; dispatch_object_t old_dou = ddi-&gt;ddi_stashed_dou; dispatch_priority_t rq_overcommit; rq_overcommit = rq-&gt;dq_priority &amp; DISPATCH_PRIORITY_FLAG_OVERCOMMIT; if (likely(!old_dou._do || rq_overcommit)) &#123; dispatch_queue_global_t old_rq = ddi-&gt;ddi_stashed_rq; dispatch_qos_t old_qos = ddi-&gt;ddi_stashed_qos; ddi-&gt;ddi_stashed_rq = rq; ddi-&gt;ddi_stashed_dou = dou; ddi-&gt;ddi_stashed_qos = qos; _dispatch_debug(&quot;deferring item %p, rq %p, qos %d&quot;, dou._do, rq, qos); if (rq_overcommit) &#123; ddi-&gt;ddi_can_stash = false; &#125; if (likely(!old_dou._do)) &#123; return; &#125; // push the previously stashed item qos = old_qos; rq = old_rq; dou = old_dou; &#125; &#125;#endif#if HAVE_PTHREAD_WORKQUEUE_QOS if (_dispatch_root_queue_push_needs_override(rq, qos)) &#123; return _dispatch_root_queue_push_override(rq, dou, qos); &#125;#else (void)qos;#endif _dispatch_root_queue_push_inline(rq, dou, dou, 1);&#125; dispatch_barrier1234567891011121314151617181920212223242526272829303132333435363738dispatch_barrier_async(dispatch_queue_t dq, dispatch_block_t work)&#123; dispatch_continuation_t dc = _dispatch_continuation_alloc(); uintptr_t dc_flags = DC_FLAG_CONSUME | DC_FLAG_BARRIER; dispatch_qos_t qos; qos = _dispatch_continuation_init(dc, dq, work, 0, dc_flags); _dispatch_continuation_async(dq, dc, qos, dc_flags);&#125;voiddispatch_async(dispatch_queue_t dq, dispatch_block_t work)&#123; dispatch_continuation_t dc = _dispatch_continuation_alloc(); uintptr_t dc_flags = DC_FLAG_CONSUME; dispatch_qos_t qos; qos = _dispatch_continuation_init(dc, dq, work, 0, dc_flags); _dispatch_continuation_async(dq, dc, qos, dc-&gt;dc_flags);&#125;// _dispatch_continuation_asyncDISPATCH_ALWAYS_INLINEstatic inline void_dispatch_continuation_async(dispatch_queue_class_t dqu, dispatch_continuation_t dc, dispatch_qos_t qos, uintptr_t dc_flags)&#123;#if DISPATCH_INTROSPECTION if (!(dc_flags &amp; DC_FLAG_NO_INTROSPECTION)) &#123; _dispatch_trace_item_push(dqu, dc); &#125;#else (void)dc_flags;#endif return dx_push(dqu._dq, dc, qos);&#125; è¿™é‡Œä¼šæœ‰ä¸ª DC_FLAG_BARRIERæ ‡è¯†ä½ã€‚å¯ä»¥çœ‹åˆ°dispatch_barrier_async å’Œ dispatch_async çš„ä¸»è¦ä¸»è¦åŒºåˆ«åœ¨äºdc_flags dispatch_oncedispatch_semaphoredispatch_groupå¤šçº¿ç¨‹åº”ç”¨traget queuedispatch_queue_set_specific/dispatch_get_specificdispatch Sourcedispatch Timerdispatch_block_wait/dispatch_block_notifydispatch_group_wait/dispatch_group_notifyä¸€äº›é—®é¢˜æ­»é”åœºæ™¯é˜Ÿåˆ—/çº¿ç¨‹å…³ç³»åŠç®¡ç†æ¨¡å‹æ³¨æ„äº‹é¡¹ç›¸å…³æ–‡çŒ® Threading Programming Guide Concurrency Programming Guide GCD Internals iOSæ¢ç´¢ å¤šçº¿ç¨‹ä¹‹GCDåº•å±‚åˆ†æ æ·±å…¥ç†è§£GCDä¹‹dispatch_queue | NeroXieçš„ä¸ªäººåšå®¢ GCDä¹‹çº¿ç¨‹åŸç†å‘ | é€†æ°´è¡ŒèˆŸ","categories":[],"tags":[{"name":"GCD","slug":"GCD","permalink":"http://deeer.github.io/tags/GCD/"}]}],"categories":[],"tags":[{"name":"GCD","slug":"GCD","permalink":"http://deeer.github.io/tags/GCD/"}]}